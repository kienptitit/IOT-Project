{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7070355,"sourceType":"datasetVersion","datasetId":4071569},{"sourceId":7071839,"sourceType":"datasetVersion","datasetId":4072668},{"sourceId":7188172,"sourceType":"datasetVersion","datasetId":4155853},{"sourceId":7190804,"sourceType":"datasetVersion","datasetId":4108367}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport os\nfrom torch.utils.data import Dataset,DataLoader,random_split\nimport torch.nn as nn\nfrom transformers import SwinForImageClassification, Trainer, TrainingArguments\nfrom transformers import Trainer, TrainingArguments\nfrom transformers import AutoFeatureExtractor\nfrom PIL import Image\nimport numpy as np\nimport torchvision\nimport matplotlib.pyplot as plt\nfrom torchvision import models","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-13T17:30:53.562757Z","iopub.execute_input":"2023-12-13T17:30:53.563056Z","iopub.status.idle":"2023-12-13T17:30:53.568877Z","shell.execute_reply.started":"2023-12-13T17:30:53.563030Z","shell.execute_reply":"2023-12-13T17:30:53.567974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset Class","metadata":{}},{"cell_type":"code","source":"class PlantDataset(Dataset):\n    def __init__(self,imgs_path,n_x,feature_extractor):\n        super().__init__()\n        self.n_x = n_x\n        self.feature_extractor = feature_extractor\n        self.imgs_list = []\n        for class_name in os.listdir(imgs_path):\n            class_path = os.path.join(imgs_path,class_name)\n            imgs_name = [os.path.join(class_path,img_name) for img_name in os.listdir(class_path)]\n            imgs_name.sort()\n            new_imgs_name = imgs_name.copy()\n            if len(imgs_name) < n_x+1:\n                d = (n_x + 1) // len(imgs_name) - 1\n                r = (n_x + 1) % len(imgs_name)\n                i = 0\n                for idx in range(len(imgs_name)):\n                    for fre in ragne(d):\n                        new_imgs_name.insert(i,imgs_name[idx])\n                    i += d + 1 \n                for idx in range(r):\n                    new_imgs_name.insert(len(imgs_name),imgs_name[-1])\n            for idx in range(len(new_imgs_name) - n_x):\n                self.imgs_list.append(new_imgs_name[idx:idx + n_x + 1])\n        \n    def __len__(self):\n        return len(self.imgs_list)\n    \n    def __getitem__(self,idx):\n        img_X = [Image.open(img_path) for img_path in self.imgs_list[idx][:-1]]\n        img_X = self.feature_extractor([img.convert('RGB') for img in img_X],return_tensor = 'pt').pixel_values\n        img_X = torch.from_numpy(np.stack(img_X))\n        img_Y = self.feature_extractor(Image.open(self.imgs_list[idx][-1]).convert('RGB'),return_tensor = 'pt').pixel_values\n        img_Y = torch.from_numpy(img_Y[0])\n        return img_X,img_Y\n","metadata":{"execution":{"iopub.status.busy":"2023-12-13T17:35:08.413318Z","iopub.execute_input":"2023-12-13T17:35:08.413754Z","iopub.status.idle":"2023-12-13T17:35:11.150298Z","shell.execute_reply.started":"2023-12-13T17:35:08.413720Z","shell.execute_reply":"2023-12-13T17:35:11.149169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Plants-Grow Network","metadata":{}},{"cell_type":"code","source":"class Decoder(nn.Module):\n    def __init__(self):\n        super(Decoder, self).__init__()\n        \n        self.conv1 = nn.ConvTranspose2d(16, 32, 2, 2, 1)\n        self.conv2 = nn.ConvTranspose2d(32, 64, 4, 2, 1)\n        self.conv3 = nn.ConvTranspose2d(64, 128, 4, 2, 1)\n        self.conv4 = nn.ConvTranspose2d(128, 64, 4, 2, 1)\n        self.conv5 = nn.ConvTranspose2d(64, 3, 4, 2, 1)\n        self.relu = nn.ReLU()\n        self.tanh = nn.Tanh()\n        \n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = self.relu(self.conv4(x))\n        x = self.relu(self.conv5(x))\n        return self.tanh(x)\n\nclass Identity(nn.Module):\n    def __init__(self):\n        super().__init__()\n    def forward(self,x):\n        return x\n\n    \nclass MyModel(nn.Module):\n    def __init__(self,in_feature,pretrain_swin):\n        super().__init__()\n        self.swin_model = SwinForImageClassification.from_pretrained(pretrain_swin)\n        self.swin_model.classifier = Identity() \n        self.swin_model.eval()\n        self.in_feature = in_feature\n        self.lstm_model = nn.LSTM(in_feature,in_feature,batch_first = True)\n        self.deconv2D = Decoder()\n        self.map_model = nn.Sequential(\n            nn.Linear(1024,256),\n            nn.ReLU(),\n            nn.Linear(256,1024)\n        )\n        \n\n    def forward(self,x):\n        \"\"\"\n        x : [B,N,C,224,224]\n        \"\"\"\n        b,n,c,h,w = x.shape\n        x = x.reshape(-1,c,h,w)\n        with torch.no_grad():\n            x_ = self.swin_model(x).logits # B*N,1024\n        \n        x_ = x_.reshape(b,n,-1)\n        \n        x_lstm,_ = self.lstm_model(x_) # B,N,1024\n        x_lstm = x_lstm[:,-1] # B,1024\n        x_encoded = self.map_model(x_lstm).reshape(b,16,8,8)\n        output = self.deconv2D(x_encoded) # B,3,224,224\n        return output","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Simase Network","metadata":{}},{"cell_type":"code","source":"class Simase_network(nn.Module):\n    def __init__(self,in_features,pretrained_swin,pretrained_AE):\n        super().__init__()\n        self.in_features = in_features\n        self.swin_model = SwinForImageClassification.from_pretrained(pretrained_swin)\n        self.swin_model.classifier = Identity() \n        self.swin_model.eval()\n        self.AE_model = MyModel(1024,pretrained_swin)\n        self.AE_model.load_state_dict(torch.load(pretrained_AE))\n        self.AE_model.eval()\n        self.simase_netword = nn.Sequential(\n            nn.Linear(self.in_features * 2,64),\n            nn.ReLU(),\n            nn.Linear(64,1),\n            nn.Sigmoid()\n        )\n    def forward(self,x,x_positive):\n        b,n,c,h,w = x.shape\n        \n        with torch.no_grad():\n            output = self.AE_model(x) # B,C,H,W\n            \n        x = x.reshape(-1,c,h,w) # B*N,C,H,W\n        \n        x = torch.concat([x,x_positive,output],dim = 0)\n        with torch.no_grad():\n            x_ = self.swin_model(x).logits # B*N + B + B,1024     \n            \n         \n        anchor = x_[-b:] # B,1024\n        x_positive = x_[-2*b:-b] # B,1024\n        x_negative = x_[:-2*b].reshape(b,-1,self.in_features) # B,N,1024\n        gap_positive = torch.concat([anchor,x_positive],dim = 1)\n        gap_negative = torch.concat([anchor.unsqueeze(1).repeat(1,n,1),x_negative],dim = -1).reshape(-1,self.in_features * 2)\n\n        labels = torch.hstack([torch.tensor([0] * len(gap_positive)),torch.tensor([1] * len(gap_negative))])\n        gap = torch.concat([gap_positive,gap_negative],dim = 0)\n        output_simase = self.simase_netword(gap)\n        return output_simase,labels\n        \n        ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DataLoader","metadata":{}},{"cell_type":"code","source":"n_x = 3\nmodel_name = 'microsoft/swin-base-patch4-window7-224'\nfeature_extractor = AutoFeatureExtractor.from_pretrained(model_name)\ndata = PlantDataset(\"/kaggle/input/plants-data/Plants-Grow\",n_x,feature_extractor)\ntrain_size = int(0.8 * len(data)) \ntest_size = len(data) - train_size\ntrain_dataset, test_dataset = random_split(data, [train_size, test_size])\ndata_loader = DataLoader(data,batch_size = 2,shuffle = True)\ntrain_loader = DataLoader(train_dataset,batch_size = 2,shuffle = True)\nval_loader = DataLoader(data,batch_size = 2,shuffle = True)","metadata":{"execution":{"iopub.status.busy":"2023-12-13T17:31:06.426493Z","iopub.execute_input":"2023-12-13T17:31:06.427030Z","iopub.status.idle":"2023-12-13T17:31:06.596212Z","shell.execute_reply.started":"2023-12-13T17:31:06.426994Z","shell.execute_reply":"2023-12-13T17:31:06.595231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train Simaese","metadata":{}},{"cell_type":"code","source":"def train_epoch_Simase(model,epoch,train_loader,criterion,optimizer):\n    model.train()\n    losses = 0.0\n    true_pred = 0\n    total_true_positive = 0\n    total_true_negative = 0\n    total_positive = 0\n    total_negative = 0\n    total = 0\n    for idx,data in enumerate(train_loader):\n        X = data[0].to('cuda')\n        y = data[1].to('cuda')\n        y_pred,labels = model(X,y)\n        y_pred = y_pred.squeeze()\n        labels = labels.float()\n        labels = labels.to('cuda')\n        y_hat = torch.round(y_pred)\n        true_pred += (labels == y_hat).detach().cpu().sum().item()\n        total += len(y_hat)\n        \n        loss = criterion(y_pred,labels)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        losses += loss.detach().cpu().item()\n        \n        negative_index = torch.where(labels == 1)[0]\n        positive_index = torch.where(labels == 0)[0]\n        \n        true_positive = torch.sum(y_hat[positive_index] == torch.tensor(0.0)).detach().cpu().item()\n        true_negative = torch.sum(y_hat[negative_index] == torch.tensor(1.0)).detach().cpu().item()\n        \n        total_true_positive += true_positive\n        total_true_negative += true_negative\n        \n        total_positive += len(positive_index)\n        total_negative += len(negative_index)\n        \n\n        \n        if idx % 1 == 0:\n            print(f\"Epoch:{epoch} Batch:{idx} Loss:{loss.item()}\")\n    print(f\"Done Epoch {epoch}, Loss: {losses/len(train_loader)} Acc : {true_pred / total * 100 :.2f} Acc_pos :{total_true_positive / total_positive} Acc_neg :{total_true_negative/total_negative}\")\n    return losses / len(train_loader), true_pred / total,total_true_positive / total_positive, total_true_negative / total_negative\n\ndef val_epoch_Simase(model,epoch,val_loader,criterion):\n    model.eval()\n    losses = 0.0\n    true_pred = 0\n    total_true_positive = 0\n    total_true_negative = 0\n    total_positive = 0\n    total_negative = 0\n    total = 0\n    for idx,data in enumerate(val_loader):\n        X = data[0].to('cuda')\n        y = data[1].to('cuda')\n        with torch.no_grad():\n            y_pred,labels = model(X,y)\n        y_pred = y_pred.squeeze()\n        labels = labels.float()\n        labels = labels.to('cuda')\n        y_hat = torch.round(y_pred)\n        true_pred += (labels == y_hat).detach().cpu().sum().item()\n        total += len(y_hat)        \n        loss = criterion(y_pred,labels)\n        losses += loss.detach().cpu().item()\n        \n        negative_index = torch.where(labels == 1)[0]\n        positive_index = torch.where(labels == 0)[0]\n        \n        true_positive = torch.sum(y_hat[positive_index] == torch.tensor(0.0)).detach().cpu().item()\n        true_negative = torch.sum(y_hat[negative_index] == torch.tensor(1.0)).detach().cpu().item()\n        \n        print('y_pred:',y_hat.detach().cpu().numpy())\n        total_true_positive += true_positive\n        total_true_negative += true_negative\n        \n        total_positive += len(positive_index)\n        total_negative += len(negative_index)\n        \n    print(f\"Done Validate Epoch {epoch}, Loss: {losses/len(val_loader)} Acc : {true_pred / total * 100 :.2f} Acc_pos :{total_true_positive / total_positive} Acc_neg :{total_true_negative/total_negative}\")\n    print(\"______________________________________________________\")\n    return losses/len(val_loader),true_pred / total\n    ","metadata":{"execution":{"iopub.status.busy":"2023-12-13T17:31:08.774345Z","iopub.execute_input":"2023-12-13T17:31:08.774698Z","iopub.status.idle":"2023-12-13T17:31:08.792716Z","shell.execute_reply.started":"2023-12-13T17:31:08.774671Z","shell.execute_reply":"2023-12-13T17:31:08.791690Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_sim = Simase_network(1024, \"/kaggle/input/swin-checkpoint/Checkpoint-Swin\",'/kaggle/input/ae-model/model_plants_grow.pt').cuda()\noptimizer = torch.optim.Adam(model_sim.parameters(),lr = 0.001)\n# weights = torch.tensor([1.0] * 2 + [0.333] * 6).cuda()\ncriterion_BCE = nn.BCELoss()\nepochs = 100\nbest_acc_pos = 0.0\n\ntrain_losses = []\ntrain_accs = []\ntrain_accs_pos = []\ntrain_accs_neg = []\n\nfor epoch in range(epochs):\n    train_loss,train_acc,acc_pos,acc_neg = train_epoch_Simase(model_sim,epoch,data_loader,criterion_BCE,optimizer)\n    if acc_pos > best_acc_pos:\n        best_acc_pos = acc_pos\n        torch.save(model_sim.state_dict(),f'model_simaese_{epoch}.pt')\n    train_losses.append(train_loss)\n    train_accs.append(train_acc)\n    train_accs_pos.append(acc_pos)\n    train_accs_neg.append(acc_neg)","metadata":{"execution":{"iopub.status.busy":"2023-12-13T17:41:46.654061Z","iopub.execute_input":"2023-12-13T17:41:46.655043Z","iopub.status.idle":"2023-12-13T17:46:08.630849Z","shell.execute_reply.started":"2023-12-13T17:41:46.655008Z","shell.execute_reply":"2023-12-13T17:46:08.629283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train Plants-Grow","metadata":{}},{"cell_type":"code","source":"def train_epoch(model,epoch,train_loader,criterion_AE,optimizer):\n    model.train()\n    losses_AE = 0.0\n    for idx,data in enumerate(train_loader):\n        X = data[0].to('cuda')\n        y = data[1].to('cuda')\n        y_pred =  model(X)\n        loss = criterion_AE(y_pred,y)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        losses_AE += loss.detach().cpu().item()\n        if idx % 1 == 0:\n            print(f\"Epoch:{epoch} Batch:{idx} Loss_AE:{loss.item()} \")\n    print(f\"Done Epoch {epoch}, Loss_AE: {losses_AE/len(train_loader)}\")\n    print(\"______________________________________________________\")\ndef generate_pred(model,train_loader):\n    model.eval()\n    imgs = []\n    for idx,data in enumerate(train_loader):\n        X = data[0].to('cuda')\n        \n        y = model(X)\n        imgs.append(y.cpu())\n        \n    imgs = torch.concat(imgs,dim = 0)[:16]\n    data_img = torchvision.utils.make_grid(imgs,nrow=4)\n    return data_img\n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 500\n\nmodel = MyModel(1024,\"/kaggle/input/swin-checkpoint/Checkpoint-Swin\").to('cuda')\noptimizer = torch.optim.Adam(model.parameters(),lr = 0.001)\ncriterion_AE = nn.L1Loss()\nfor epoch in range(epochs):\n    train_epoch(model,epoch,data_loader,criterion_AE,optimizer)\n    if epoch % 5 == 0:\n        plt.figure()\n        data_img =generate_pred(model,data_loader).detach().cpu()\n        plt.imshow(data_img.permute(1,2,0))\n        plt.axis('off')\n        plt.show()\n        plt.close()\n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_pred_new(model,train_loader):\n    model.eval()\n    imgs = []\n    mean = [0.485, 0.456, 0.406]\n    std = [0.229, 0.224, 0.225]\n\n    for idx,data in enumerate(train_loader):\n        X = data[0].to('cuda')\n        \n        y = model(X)\n        for i in range(3):  # Loop over each channel\n            y[:, i, :, :] *= std[i]\n            y[:, i, :, :] += mean[i]\n\n        imgs.append(y.cpu())\n    imgs = torch.concat(imgs,dim = 0)\n    data_img = torchvision.utils.make_grid(imgs,nrow=4)\n    return data_img\n\ndata_img = generate_pred_new(model,data_loader).detach().cpu()\nplt.imshow(data_img.permute(1,2,0))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict(),'new_model_plants_grow.pt')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}