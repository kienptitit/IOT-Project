{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7044140,"sourceType":"datasetVersion","datasetId":4053200},{"sourceId":7049229,"sourceType":"datasetVersion","datasetId":4056663}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport torch\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torchvision\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset,DataLoader\nimport cv2\nimport random\nimport torch.nn as nn\nfrom transformers import AutoFeatureExtractor\nfrom datasets import load_dataset,load_metric\nimport shutil\nfrom transformers import SwinForImageClassification, Trainer, TrainingArguments\nfrom transformers import Trainer, TrainingArguments\nfrom PIL import Image","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-27T15:01:55.765116Z","iopub.execute_input":"2023-11-27T15:01:55.766532Z","iopub.status.idle":"2023-11-27T15:01:55.773922Z","shell.execute_reply.started":"2023-11-27T15:01:55.766487Z","shell.execute_reply":"2023-11-27T15:01:55.772648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_path = \"data\"\ndata_set = [\"train\",\"test\"]\noriginal_folder = \"/kaggle/input/plants-classification/data\"\ntrain_folder = os.path.join(data_path,\"train\")\ntest_folder = os.path.join(data_path,\"test\")\n\nif not os.path.exists(data_path):\n    os.mkdir(data_path)\n    \nfor d in data_set:\n    if not os.path.exists(os.path.join(data_path,d)):\n        os.mkdir(os.path.join(data_path,d))\n\nfor class_name in os.listdir(original_folder):\n    class_path = os.path.join(original_folder,class_name)\n    class_train_path = os.path.join(train_folder,class_name)\n    class_test_path = os.path.join(test_folder,class_name)\n\n    if not os.path.exists(class_train_path):\n        os.mkdir(class_train_path)\n    if not os.path.exists(class_test_path):\n        os.mkdir(class_test_path)\n    imgs_name = os.listdir(class_path)\n    n_train = int(len(imgs_name) * 0.8)\n    \n    for img_name in imgs_name[:n_train]:\n        img_path = os.path.join(class_path,img_name)\n        new_img_path = os.path.join(class_train_path,img_name)\n        shutil.copy(img_path,new_img_path)\n    \n    for img_name in imgs_name[n_train:]:\n        img_path = os.path.join(class_path,img_name)\n        new_img_path = os.path.join(class_test_path,img_name)\n        shutil.copy(img_path,new_img_path)\n    \n        ","metadata":{"execution":{"iopub.status.busy":"2023-11-27T15:01:57.788349Z","iopub.execute_input":"2023-11-27T15:01:57.788712Z","iopub.status.idle":"2023-11-27T15:02:14.089034Z","shell.execute_reply.started":"2023-11-27T15:01:57.788677Z","shell.execute_reply":"2023-11-27T15:02:14.088197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = load_dataset(\"/kaggle/working/data\")","metadata":{"execution":{"iopub.status.busy":"2023-11-27T15:02:24.100258Z","iopub.execute_input":"2023-11-27T15:02:24.100657Z","iopub.status.idle":"2023-11-27T15:02:25.319727Z","shell.execute_reply.started":"2023-11-27T15:02:24.100600Z","shell.execute_reply":"2023-11-27T15:02:25.318865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_name= 'microsoft/swin-base-patch4-window7-224'\nfeature_extractor = AutoFeatureExtractor.from_pretrained(model_name)\n\ndef transform(example_batch):\n    # Take a list of PIL images and turn them to pixel values\n    inputs = feature_extractor([x.convert('RGB') for x in example_batch['image']], return_tensors='pt')\n    inputs['label'] = example_batch['label']\n    return inputs\n\nprepared_ds = data.with_transform(transform)","metadata":{"execution":{"iopub.status.busy":"2023-11-27T15:02:25.611130Z","iopub.execute_input":"2023-11-27T15:02:25.612038Z","iopub.status.idle":"2023-11-27T15:02:25.964798Z","shell.execute_reply.started":"2023-11-27T15:02:25.611996Z","shell.execute_reply":"2023-11-27T15:02:25.963971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def collate_fn(batch):  \n    return {\n        'pixel_values': torch.stack([x['pixel_values'] for x in batch]),\n        'labels': torch.tensor([x['label'] for x in batch])\n    }\n\nmetric = load_metric(\"accuracy\")\ndef compute_metrics(p):\n    return metric.compute(predictions=np.argmax(p.predictions, axis=1), references=p.label_ids)","metadata":{"execution":{"iopub.status.busy":"2023-11-27T15:02:28.045739Z","iopub.execute_input":"2023-11-27T15:02:28.046433Z","iopub.status.idle":"2023-11-27T15:02:28.699588Z","shell.execute_reply.started":"2023-11-27T15:02:28.046397Z","shell.execute_reply":"2023-11-27T15:02:28.698703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = data['train'].features['label'].names\n\nmodel = SwinForImageClassification.from_pretrained(\n    model_name,\n    num_labels=len(labels),\n    id2label={str(i): c for i, c in enumerate(labels)},\n    label2id={c: str(i) for i, c in enumerate(labels)},\n    ignore_mismatched_sizes = True,\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-27T15:02:30.221501Z","iopub.execute_input":"2023-11-27T15:02:30.222215Z","iopub.status.idle":"2023-11-27T15:02:41.705987Z","shell.execute_reply.started":"2023-11-27T15:02:30.222179Z","shell.execute_reply":"2023-11-27T15:02:41.705031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 16\n\ntraining_args = TrainingArguments(\n    f\"swin-finetuned-plants-classification\",\n    remove_unused_columns=False,\n    evaluation_strategy = \"epoch\",\n    save_strategy = \"epoch\",\n    learning_rate=5e-5,\n    per_device_train_batch_size=batch_size,\n    gradient_accumulation_steps=4,\n    per_device_eval_batch_size=batch_size,\n    num_train_epochs=100,\n    warmup_ratio=0.1,\n    logging_steps=10,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"accuracy\",\n#     push_to_hub=True,\n)\n\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    data_collator=collate_fn,\n    compute_metrics=compute_metrics,\n    train_dataset=prepared_ds[\"train\"],\n    eval_dataset=prepared_ds[\"test\"],\n    tokenizer=feature_extractor,\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-27T15:02:53.829032Z","iopub.execute_input":"2023-11-27T15:02:53.829927Z","iopub.status.idle":"2023-11-27T15:02:59.807281Z","shell.execute_reply.started":"2023-11-27T15:02:53.829892Z","shell.execute_reply":"2023-11-27T15:02:59.806095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_results = trainer.train()\ntrainer.save_model()\ntrainer.log_metrics(\"train\", train_results.metrics)\ntrainer.save_metrics(\"train\", train_results.metrics)\ntrainer.save_state()\n\n\nmetrics = trainer.evaluate(prepared_ds['test'])\ntrainer.log_metrics(\"eval\", metrics)\ntrainer.save_metrics(\"eval\", metrics)","metadata":{"execution":{"iopub.status.busy":"2023-11-27T15:03:05.683233Z","iopub.execute_input":"2023-11-27T15:03:05.683619Z","iopub.status.idle":"2023-11-27T15:21:56.999376Z","shell.execute_reply.started":"2023-11-27T15:03:05.683584Z","shell.execute_reply":"2023-11-27T15:21:56.997523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_ = SwinForImageClassification.from_pretrained(\"/kaggle/working/swin-finetuned-plants-classification/checkpoint-139\")\nimg = Image.open(\"/kaggle/working/data/test/31/2.jpg\")\nimg = feature_extractor(img.convert('RGB'), return_tensors=\"pt\")\nmodel_.eval()\nwith torch.no_grad():\n    pred = model_(**img).logits.argmax(-1).item()\n    print(model.config.id2label[str(pred)])","metadata":{"execution":{"iopub.status.busy":"2023-11-25T14:52:32.601269Z","iopub.execute_input":"2023-11-25T14:52:32.601662Z","iopub.status.idle":"2023-11-25T14:52:33.751350Z","shell.execute_reply.started":"2023-11-25T14:52:32.601631Z","shell.execute_reply":"2023-11-25T14:52:33.750203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python ","metadata":{"execution":{"iopub.status.busy":"2023-11-25T15:47:23.321555Z","iopub.execute_input":"2023-11-25T15:47:23.321979Z","iopub.status.idle":"2023-11-25T15:47:27.626412Z","shell.execute_reply.started":"2023-11-25T15:47:23.321945Z","shell.execute_reply":"2023-11-25T15:47:27.625127Z"},"trusted":true},"execution_count":null,"outputs":[]}]}